from scholarly import scholarly, ProxyGenerator
import json
import time
from pathlib import Path
from datetime import datetime
import requests

def get_publications(author_id):
    try:
        print("ðŸš€ Starting test.py")
        # Force scholarly to use requests
        scholarly._session = requests.Session()
        author = scholarly.search_author_id(author_id)
        author_filled = scholarly.fill(author, sections=['publications'])
        return author_filled.get("publications", [])
    except Exception as e:
        print(f"Error: {str(e)}")
        return []


def get_current_year_publications(publications):
    pub_data = []
    current_year = datetime.now().year
    
    # Filter and process ALL current year publications
    for pub in publications:
        try:
            # Skip if not current year
            pub_year = int(pub.get("bib", {}).get("pub_year", "0"))
            if pub_year != current_year:
                continue
                
            time.sleep(1)  # Maintain rate limiting
            filled_pub = scholarly.fill(pub)
            bib = filled_pub.get("bib", {})
            
            # Original author processing
            authors = bib.get("author", "N/A")
            if isinstance(authors, list):
                authors = ", ".join(authors)

            # Original venue priority chain
            venue = bib.get("venue") or \
                   bib.get("journal") or \
                   bib.get("conference") or \
                   bib.get("booktitle") or \
                   bib.get("source", "N/A")

            # Original output structure
            pub_data.append({
                "title": bib.get("title", "N/A"),
                "authors": authors,
                "publication_year": current_year,
                "citations": filled_pub.get("num_citations", 0),
                "venue": venue,
                "source_link": filled_pub.get("pub_url", ""),
                "doi": filled_pub.get("pub_url", "")
            })
            
        except Exception as e:
            print(f"Skipping publication: {e}")
            continue
            
    return pub_data

def save_to_json(data, filename):
    data_dir = Path(__file__).parent.parent
    data_dir.mkdir(exist_ok=True)
    with open(data_dir / filename, "w") as f:
        json.dump(data, f, indent=2)

def main():
    author_id = "cyQLH48AAAAJ"
    
    publications = get_publications(author_id)
    pub_data = get_current_year_publications(publications)
    save_to_json(pub_data, "publications.json")
    print(f"âœ… Retrieved {len(pub_data)} publications")
    print(f"ðŸ“„ Saved to: {Path(__file__).parent / 'publications.json'}")

if __name__ == "__main__":
    main()
